{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_딥러닝의 진화.ipynb","provenance":[],"authorship_tag":"ABX9TyNmOzPrAjsRZNJSKXx0OYkL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uyOeODQHg-UC"},"source":["### **2012** \n","* CNN중 Alex net이라는 네트워크 구조 \n","* Alext net이 1등을 차지 -> CNN이 유명해지게 됨 \n"]},{"cell_type":"markdown","metadata":{"id":"hn2c2yCDiW-9"},"source":["### **2013**\n","* 아타리 게임\n","- 학습이 많이 진행 -> 구석을 파서 공을 위로 올림\n","- 딥마인드 -> 구글에 인수 -> 알파고 \n"]},{"cell_type":"markdown","metadata":{"id":"Qr_JB_Kdip82"},"source":["### **2014**\n","* RNN이라는 네트워크를 사용하여 중국어 -> 영어로 번역 \n","* 성능의 한계가 생김 \n","* attention 모델의 출현 성능이 급격히 좋아짐 "]},{"cell_type":"markdown","metadata":{"id":"mNiT9J3XjQOe"},"source":["### **adam optimizer**\n","- Gradient Descent를 개선 \n","- 대중적인 알고리즘 \n","- 잘 모를땐 adam을 사용하면 됨 \n"]},{"cell_type":"markdown","metadata":{"id":"_FKNjTxlj4eW"},"source":["### **2015**\n","* GANs\n","* 오바마 합성 사진 "]},{"cell_type":"markdown","metadata":{"id":"rJB5YKjHkHj-"},"source":["* Residual Networks(ResNet)\n","* CNN의 종류 중 하나 \n","* 사람이 이미지를 찾는 테스트 -> 5% 오차률 \n","* 3% 벽을 깨트림 -> 사람보다 뛰어남 \n","* 152레이어 -> 진정한 딥러닝의 길"]},{"cell_type":"markdown","metadata":{"id":"jZO3uW07kxlW"},"source":["### **2016**\n","* 알파고 \n","* 이세돌 9단이 컴퓨터를 이긴 마지막 인류 "]},{"cell_type":"markdown","metadata":{"id":"KUYAG2Yuk9jl"},"source":["### **2017**\n","* Transformer - 번역 모델 \n","* RNN의 단점을 극복 -> 병렬처리를 하지 못함 \n","* attention만으로 만든 모델 \n","* 자연어를 정복\n","* 딥러닝에서 가장 중요한 모델 중 하나 "]},{"cell_type":"markdown","metadata":{"id":"tPfkxi2_lirN"},"source":["### **2018**\n","* BERT\n","* Transformer에서 인코더만 따온 모델 \n","* 자연어를 정답없이 사용(인터넷 문장들의 데이터를 삽입)\n","* 일부 글자를 가리고 가린 부분을 맞출수 있도록 학습\n","* 모델을 크게 만들고 엄청난 데이터를 사용\n","* 적은 데이터(정답)를 가지고 다시 학습 \n"]},{"cell_type":"markdown","metadata":{"id":"1V_A1BJFmkPO"},"source":["### **2019/2020**\n","- GPU 수천대를 사용하여 큰 모델을 만듬\n","- 정답을 필요없이 실제 데이터만으로 셀프 수퍼바이즈 러닝 "]}]}